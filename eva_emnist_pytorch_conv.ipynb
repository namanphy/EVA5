{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eva_emnist_pyotch_conv.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMaCgW8pAceHc05PXl9jyT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namanphy/EVA5/blob/main/eva_emnist_pytorch_conv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj3qRnbqgGPC"
      },
      "source": [
        "import torch\r\n",
        "import numpy\r\n",
        "import torchvision\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch import nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufIvGPnaPyO8"
      },
      "source": [
        "## Loading Our EMINIST Data\r\n",
        "\r\n",
        "Following two steps are involved : \r\n",
        "\r\n",
        "1. Loading the dataset from Pytorch\r\n",
        "2. Making a dataloader for the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBAq9_9Br4r6"
      },
      "source": [
        "###### Loading the data - EMNIST , split='mnist'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMYa1qIRP-3p"
      },
      "source": [
        "train_set = torchvision.datasets.EMNIST('./',\r\n",
        "                                        train=True,\r\n",
        "                                        download=True,\r\n",
        "                                        split='mnist',\r\n",
        "                                        transform=torchvision.transforms.Compose([\r\n",
        "                                                                    torchvision.transforms.ToTensor()                                                       \r\n",
        "                                        ]))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlM6_L5FRn6f",
        "outputId": "e62cba88-9d49-4695-ceed-daeec7b6d8e9"
      },
      "source": [
        "len(train_set), train_set.targets.bincount()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivwluqvtrTIT"
      },
      "source": [
        "###### Let's see the first sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "QLYe9qGSUX77",
        "outputId": "975a9951-b171-4d91-ef74-82c7f9fb7b5e"
      },
      "source": [
        "sample = next(iter(train_set))\r\n",
        "print(sample[0].shape)\r\n",
        "plt.imshow(sample[0].squeeze(0))\r\n",
        "print(\"LABEL : \", sample[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "LABEL :  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xDV8QkUrwkd"
      },
      "source": [
        "###### Making our data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b7pnGDMrc66"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
        "\r\n",
        "torch.manual_seed(1)\r\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_set,\r\n",
        "                                           batch_size=1000,\r\n",
        "                                           shuffle=True, **kwargs)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFR4LrAmQ2cL"
      },
      "source": [
        "sample = next(iter(train_loader))\r\n",
        "len(sample[0]), sample[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVsrEFx5axTg"
      },
      "source": [
        "## Making our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLPKt3H9twCg",
        "outputId": "26c01f21-3520-4594-ac7e-ca86251f6947"
      },
      "source": [
        "torch.set_grad_enabled(False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fb1c4efd908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lQwUQNzat4H"
      },
      "source": [
        "class Model(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1) # input - (28 x 28 x 1), Output - (28 x 28 x 10), RF - 3x3\r\n",
        "        self.conv2 = nn.Conv2d(10, 20, 3, padding=1)  # input - (28 x 28 x 10), Output - (28 x 28 x 20), RF - 5x5\r\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)    # input - (28 x 28 x 20), Output - (14 x 14 x 20), RF - 10x10\r\n",
        "        self.conv3 = nn.Conv2d(20, 30, 3, padding=1)  # input - (14 x 14 x 20), Output - (14 x 14 x 30), RF - 12x12\r\n",
        "        self.conv4 = nn.Conv2d(30, 30, 3, padding=1)  # input - (14 x 14 x 30), Output - (14 x 14 x 30), RF - 14x14\r\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)    # input - (14 x 14 x 30), Output - (7 x 7 x 30), RF - 28x28\r\n",
        "        self.conv5 = nn.Conv2d(30, 20, 3)  # input - (7 x 7 x 30), Output - (5 x 5 x 20), RF - 30x30\r\n",
        "        self.conv6 = nn.Conv2d(20, 10, 3)  # input - (5 x 5 x 20), Output - (3 x 3 x 10), RF - 32x32\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, t):\r\n",
        "        \r\n",
        "        # first pooling layer and 2 convulations\r\n",
        "        t = self.conv1(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        t = self.conv2(t)\r\n",
        "        t = F.relu(t)\r\n",
        "\r\n",
        "        t = self.pool1(t)\r\n",
        "\r\n",
        "        # second pooling layer and 2 convulations\r\n",
        "        t = self.conv3(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        t = self.conv4(t)\r\n",
        "        t = F.relu(t)\r\n",
        "\r\n",
        "        t = self.pool2(t)\r\n",
        "\r\n",
        "        # last convulation layers\r\n",
        "        t = self.conv5(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        t = self.conv6(t)\r\n",
        "\r\n",
        "        # GAP layer\r\n",
        "        out = t.mean(dim=[-2,-1]) # input - (3 x 3 x 10), Output - (1 x 1 x 10), RF - 32x32 -> It is a GAP layer. Implements mean over channel dimensions.\r\n",
        "\r\n",
        "        return F.softmax(out)\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pgLYHQqt56j"
      },
      "source": [
        "###### Testing out model input and outputs on single sample "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30Q3jInxa1xS",
        "outputId": "178b11df-4fe6-4db1-ffe9-bc0ce4ed47ff"
      },
      "source": [
        "sample = next(iter(train_loader))\r\n",
        "# len(sample[0]), sample[1]\r\n",
        "image, label = sample[0][0], sample[1][0]\r\n",
        "image.shape, image.unsqueeze(0).shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), torch.Size([1, 1, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kT63U3trFja",
        "outputId": "85d67149-0c12-4f72-bfa9-e33a466c73b1"
      },
      "source": [
        "model = Model()\r\n",
        "pred = model(image.unsqueeze(0))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkS7hjHSuh-n",
        "outputId": "db022d6e-cfc4-444c-f6b7-e31b9d9e7379"
      },
      "source": [
        "pred, label"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1035, 0.0960, 0.1066, 0.1041, 0.1007, 0.0972, 0.0979, 0.1008, 0.0972,\n",
              "          0.0961]]), tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQTnwjkOvUVK",
        "outputId": "d9f15bf1-53aa-48dd-bad0-ca3d77fba1d0"
      },
      "source": [
        "pred.argmax(dim=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpcr_XK7wl8F"
      },
      "source": [
        "## Creating a training loop and training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfBylLJByJDL",
        "outputId": "d6a8ac86-dfd5-4c78-e9be-6b07cea88a81"
      },
      "source": [
        "torch.set_grad_enabled(True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fb176d01b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csN7wf-NyVyy"
      },
      "source": [
        "def get_num_correct(preds, labels):\r\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQQhVyVkwd3m",
        "outputId": "1bc51383-5c9d-42fb-d5b5-e5eb19cd435d"
      },
      "source": [
        "model = Model().to(device)\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\r\n",
        "\r\n",
        "for i in range(20):\r\n",
        "    \r\n",
        "    total_loss = 0\r\n",
        "    total_correct = 0\r\n",
        "\r\n",
        "    for batch in train_loader: # Get Batch\r\n",
        "        images, labels = batch\r\n",
        "        images = images.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        preds = model(images) # Pass Batch\r\n",
        "        loss = F.cross_entropy(preds, labels) # Calculate Loss\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward() # Calculate Gradients\r\n",
        "        optimizer.step() # Update Weights\r\n",
        "\r\n",
        "        total_loss += loss.item()\r\n",
        "        total_correct += get_num_correct(preds, labels)\r\n",
        "\r\n",
        "    print(\r\n",
        "        \"epoch:\", i, \r\n",
        "        \"total_correct:\", total_correct, \r\n",
        "        \"loss:\", total_loss\r\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 total_correct: 29255 loss: 117.95919871330261\n",
            "epoch: 1 total_correct: 40077 loss: 107.44942653179169\n",
            "epoch: 2 total_correct: 40797 loss: 106.6788318157196\n",
            "epoch: 3 total_correct: 40970 loss: 106.51033985614777\n",
            "epoch: 4 total_correct: 40801 loss: 106.72469365596771\n",
            "epoch: 5 total_correct: 42797 loss: 104.70428740978241\n",
            "epoch: 6 total_correct: 46811 loss: 100.78279328346252\n",
            "epoch: 7 total_correct: 47106 loss: 100.46633815765381\n",
            "epoch: 8 total_correct: 47319 loss: 100.19122755527496\n",
            "epoch: 9 total_correct: 47418 loss: 100.07758128643036\n",
            "epoch: 10 total_correct: 47526 loss: 99.93885087966919\n",
            "epoch: 11 total_correct: 50167 loss: 97.40339589118958\n",
            "epoch: 12 total_correct: 53163 loss: 94.45706915855408\n",
            "epoch: 13 total_correct: 53232 loss: 94.38677322864532\n",
            "epoch: 14 total_correct: 53293 loss: 94.3391546010971\n",
            "epoch: 15 total_correct: 53380 loss: 94.24734461307526\n",
            "epoch: 16 total_correct: 53379 loss: 94.23817539215088\n",
            "epoch: 17 total_correct: 53419 loss: 94.19719541072845\n",
            "epoch: 18 total_correct: 53529 loss: 94.08784830570221\n",
            "epoch: 19 total_correct: 53552 loss: 94.07045292854309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oldEj4hO70Ft"
      },
      "source": [
        "As we have seen above. We have trianed the model for 20 epochs and got reduced to loss of 94. Now, to reduce the loss further, we need to select a better model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q2H-ZF169W6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}